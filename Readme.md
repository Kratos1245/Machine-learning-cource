## Содержание

[comment]: <> (6&#41; [Градиентный бустинг]&#40;https://nbviewer.jupyter.org/github/andreitsev/Machine-Learning-EF-MSU/blob/master/Lectures/Градиентный%20бустинг.ipynb&#41;)

[comment]: <> (7&#41; [Нейронные сети]&#40;https://nbviewer.jupyter.org/github/andreitsev/Machine-Learning-EF-MSU/blob/master/Lectures/NN_intro.ipynb&#41;)

| Тема | Материалы | Задания | Проверочные |
| :---: | :---: | :---: | :---: |
| Обработка данных в python | <br> [Дьяконов Базовый Python](https://drive.google.com/file/d/1aQ4dwItZNEYSlTwJjYBB3aIBUN4E2IP4/view?usp=sharing) <br> [Дьяконов Pandas](https://drive.google.com/file/d/1XEynEfIvp0R7hlCtZ74Dj8Qxbq4ASkiN/view?usp=sharing) <br> [Дьяконов Numpy](https://drive.google.com/file/d/1Bys5_lLFK_iGcY6VHdNWTTvdORdjYSmm/view?usp=sharing) <br> [Дьяконов sklearn](https://drive.google.com/file/d/1QA_9sYDVK7GiRJw_gm_Yd0Tt-T1HGi8u/view?usp=sharing) | [Курс по базовому питону](https://stepik.org/course/31182/syllabus) <br> <br> [Задачи на pandas](https://github.com/Dyakonov/visualization) <br> <br> [Задачи на numpy и pandas](https://stepik.org/course/3356/syllabus) (Неделя 2 - Векторы, Матрицы) |
| Градиентные методы оптимизации | Основные <br> [Ноутбук](https://nbviewer.jupyter.org/github/andreitsev/Machine-Learning-EF-MSU/blob/master/Lectures/Градиентные%20методы%20оптимизации.ipynb) <br>  [Лекция Дьяконова](https://drive.google.com/file/d/1tWfmpLxREVLuN7ZbwdaXA0MPjezNEU9S/view?usp=sharing) <br> [Теория по матричному дифференцированию](https://drive.google.com/file/d/1OocZpnjfYo8elHS3v1P1fHsKXT42jhO-/view?usp=sharing) <br> _________________________________ <br> Дополнительно <br> [Примеры нахождения матричных производных](https://drive.google.com/file/d/1h1n2YXC1QlkGPxJwzddhKbed33MDXMa7/view?usp=sharing) <br> [Интерактивные визуализации методов оптимизации](https://the-learning-machine.com/article/machine-learning/unconstrained-optimization) <br> [Математика в машинном обучении](https://drive.google.com/file/d/1gRVhBINgoFQHWQsUTXfZoi0BOcLDU0Th/view?usp=sharing) (225 страница, Continuous optimization)| [Семинарские задачи](https://www.overleaf.com/read/vgfsbdmssjsd) <br> <br> [Практическая](https://www.overleaf.com/read/tvmjbwbrrmyr) |
| Метрические методы | Основные <br> [Соколов KNN](https://drive.google.com/file/d/1WXuTsdGTdjNl5aZPD111klB7HiUjrbzI/view?usp=sharing) <br> [Дьяконов Метрические методы](https://drive.google.com/file/d/1An7wO3EFufOnsRur_rquShTp85OZCU3o/view?usp=sharing) <br> [Дьяконов Валидация моделей](https://drive.google.com/file/d/1lOunHT6sOKPAmOoWHiWukK1rNzNAEOiT/view?usp=sharing) <br> [Соколов KNN (с картинками)](https://drive.google.com/file/d/1AegrIBZyc0w7piKlb1fRDdlWxUEb17u_/view?usp=sharing) <br> [Соколов Обучение метрик](https://drive.google.com/file/d/1XNxnxyo_0mahN_PFglduqgTEI61aOgaV/view?usp=sharing) <br> [Соколов Приближённые методы поиска ближайших соседей](https://drive.google.com/file/d/1UrIwpIRfkfnK5GLEicFFHz8HIpHMRrsz/view?usp=sharing)  <br> _________________________________ <br> Дополнительно <br> [Ноутбук](https://nbviewer.jupyter.org/github/andreitsev/Machine-Learning-EF-MSU/blob/master/Lectures/Лекция_Метрические%20методы%20классификации%20и%20регрессии.ipynb) <br> [Соколов. Приближённый поиск ближайших соседей. NSW и HNSW](https://www.youtube.com/watch?v=Kepw20luLmw) (начиная с 40:50) <br> [Обзор методов приближённого поиска ближайших соседей](https://habr.com/en/company/mailru/blog/338360/)| [Семинарские задачи](https://www.overleaf.com/read/nwpbtbfwczpn)  | [Вариант1](https://docs.google.com/forms/d/1yJb8IW4Lr3ltYAU5XEonMiOyC1K7e9oFiThitbZyl8Y/edit) <br> _______________ <br> [Тест от Дьяконова](https://docs.google.com/forms/d/e/1FAIpQLScETwt1mfhyKTUdlm7xptqFvkF2rL_HYI2c0Q4kkWrAUQ6mig/viewform)
| Логические методы | Основные <br>  [Соколов Решающие деревья](https://drive.google.com/file/d/1l-aU5hwYwoKkJ8J9bWSDslTr0rondXOB/view?usp=sharing) <br> [Дьяконов Решающие деревья](https://drive.google.com/file/d/1eyNlV-YHIauBbogcbl4aNU5_McdAROgn/view?usp=sharing) <br> _________________________________ <br> Дополнительно <br> [Соколов деревья с картинками](https://drive.google.com/file/d/1H0PaZlZbRf6Xzgi0qM4yyHi-v0aNfkux/view?usp=sharing) <br> [Соколов Пример построения дерева](https://drive.google.com/file/d/1blrmIgJQr5KzD-7ZOwqmt59F_qp_-juM/view?usp=sharing) <br> [Uplift моделирование с помощью деревьев](https://habr.com/ru/company/ru_mts/blog/485976/) | [Семинарские задачи](https://www.overleaf.com/read/gytnbjdzgfwr) <br> <br> [Практическая](https://www.overleaf.com/read/yrwdkbnyywtv)   | [Вариант 1](https://docs.google.com/forms/d/e/1FAIpQLSc8mB9XiScYK68jhHO86eZgx9TOpPbrxVfzpdcdG3XMYwkAvg/viewform?usp=sf_link)  <br> _______________ <br> [Тест от Дьяконова](https://docs.google.com/forms/d/e/1FAIpQLSebxPEXjOL3og32H3yipSYz7GSMb6XAXXW9JYdf-jlT1GsjZQ/viewform) 
| Метрики качества | Основные <br> [Соколов Метрики качества бинарной классификации](https://drive.google.com/file/d/1-oH5QhlRydpjhEW8nXH7XBJYewdKoF23/view?usp=sharing) <br> [Дьяконов Метрики качества](https://drive.google.com/file/d/1DmVmgWQtqjrqmBwJj9b-gcmjdIXcYlp4/view?usp=sharing) <br> [Соколов Метрики качества многоклассовой классификации](https://drive.google.com/file/d/1rgHnWLhr6Yn2AkVvOL5jRDq6pqc8snHP/view?usp=sharing) <br> [Соколов ROC-AUC](https://drive.google.com/file/d/1aSkFzpJM-fHNh72CKErGB9gpxONg2z-W/view?usp=sharing) <br> _________________________________ <br> Дополнительно <br> [Дьяконов ROC-AUC](https://dyakonov.org/2017/07/28/auc-roc-площадь-под-кривой-ошибок/) <br> [Дьяконов Кривые в ML](https://dyakonov.org/2019/08/29/кривые-в-машинном-обучении/) | [Семинарские задачи](https://www.overleaf.com/read/dftcbbbympfx) | [Тест от Дьяконова (AUC)](https://docs.google.com/forms/d/e/1FAIpQLSfrZOU9TaDWIvxBabf8saK-unmijfOHwkANpARNCrVQ-g3KyQ/viewform)
| Линейные методы | Основные <br> [Соколов Обучение линейных классификаторов в общем виде](https://drive.google.com/file/d/1woYoeB3Hs4hpCR4xUzRG-9UMSXsuEDnp/view?usp=sharing) <br> [Соколов SVM и Logreg](https://drive.google.com/file/d/1gm-mHah8g3SxqAzV9-M3SRFhUQgETXax/view?usp=sharing) <br> [Дьяконов Линейные методы](https://drive.google.com/file/d/1IaDedfHY65n7UVUw9wI_-67BsQ14Nic_/view?usp=sharing) <br> [Теория SVM](https://drive.google.com/file/d/1gRVhBINgoFQHWQsUTXfZoi0BOcLDU0Th/view?usp=sharing) (370 страница, Classification with Support Vector Machines)  <br> __________________________________ <br> Дополнительно <br> [Ноутбук логрег](https://nbviewer.jupyter.org/github/andreitsev/Machine-Learning-EF-MSU/blob/master/Seminars/Демонстрация%20логистической%20регрессии.ipynb) <br> [Ноутбук по условной оптимизации и SVM](https://nbviewer.jupyter.org/github/andreitsev/Machine-Learning-EF-MSU/blob/master/Lectures/Условная%20оптимизация%20и%20SVM.ipynb) <br> [Соколов logreg с картинками](https://drive.google.com/file/d/165Imi2mxAzbFJwORFxxvcuExoB3j6VqX/view?usp=sharing) <br> [Соколов SVM с картинками](https://drive.google.com/file/d/1kBce7P73lg1DaXiVLZxLWP2rP0CFomti/view?usp=sharing)  <br> __________________________________ <br> Ликбез по условной оптимизации <br> [Условная оптимизация](https://drive.google.com/file/d/1ntD2mlob1jWemiIftkN1vSWvL_Vctrau/view?usp=sharing) <br> [Теория ККТ с примерами](https://drive.google.com/file/d/1M546yxrsD5oQT5Ek91auzGbLBCKeDPeA/view?usp=sharing) <br> [Теория двойственности](https://drive.google.com/file/d/1h106yD-wfxlfUAq7I6MyGaOKAT0pIqdB/view?usp=sharing) <br> [Заметки о решении задач условной оптимизации](https://drive.google.com/file/d/1KdtRpe1WJtJVGX6RLLWGYxbdRSbTaKR5/view?usp=sharing) | [Семинарские задачи](https://www.overleaf.com/read/fvbgqvgbhnxt) |
| Ядровые методы | Основные <br> [Соколов. Ядра 1](https://drive.google.com/file/d/1jVRsFJ_2J9Z-CSP8OS0A2zRuC_EnL-vZ/view?usp=sharing) <br> [Соколов. Ядра 2](https://drive.google.com/file/d/1LKJQinTgSUkNJKhm8Am_1YDZX4QTKBw_/view?usp=sharing) <br> [Соколов. Ядра 3](https://drive.google.com/file/d/1ywlp7dC-NA0K0bdC3dJCncHIcfuOyF3x/view?usp=sharing) <br> [Соколов. Ядра 4](https://drive.google.com/file/d/1mowSUd-iuNXjB5IANYMQz6ZEY6Bsm_na/view?usp=sharing) <br> [Математика в машинном обучении](https://drive.google.com/file/d/1gRVhBINgoFQHWQsUTXfZoi0BOcLDU0Th/view?usp=sharing) (388 страница, Kernels)| [Семинарские задачи](https://www.overleaf.com/read/swrcyzvbbcjy) | 
| Обучение без учителя | Embeddings <br> [Снижение размерности и кластеризация](https://nbviewer.jupyter.org/github/andreitsev/Machine-Learning-EF-MSU/blob/master/Lectures/Снижение%20размерности%20и%20Кластеризация.ipynb) (ноутбук) <br> [Соколов PCA](https://drive.google.com/file/d/1lkfVAdmLKDpWgNf4SetqOjZru-j2Yb6L/view?usp=sharing) <br> [Word2Vec](https://lena-voita.github.io/nlp_course/word_embeddings.html) <br> [Соколов t-SNE](https://drive.google.com/file/d/1HuB09_vrGUe9G8E_Jcw61okrGSkwUlts/view?usp=sharing) <br> [Математика в машинном обучении](https://drive.google.com/file/d/1gRVhBINgoFQHWQsUTXfZoi0BOcLDU0Th/view?usp=sharing) (стр. 317, Dimensionality Reduction with Principal Component Analysis) <br> __________________________________ <br> Кластеризация <br> [Соколов Кластеризация](https://drive.google.com/file/d/1HuB09_vrGUe9G8E_Jcw61okrGSkwUlts/view?usp=sharing) <br> [DBSCAN](https://habr.com/ru/post/322034/) <br> __________________________________ <br> Дополнительно <br> [clustering+tsne](https://colab.research.google.com/drive/16OkfhtpvioTKh1PfYT_EL80fFdnBVtb1?authuser=4) (ноутбук) <br> [Байесовский вариант PCA](https://drive.google.com/file/d/1Nq0mkvh-m7z0ggDFBrRv9XiD1nEVBEGe/view?usp=sharing) <br> [Embeddings в рекомендательных системах](https://drive.google.com/file/d/1dxbdmKlC5ilwanaXj0BoCqKC8esz1bjF/view?usp=sharing) (2.1.2 Модели со скрытыми переменными) <br> [t-SNE paper](https://drive.google.com/file/d/1kiUYHee5FJWz74mtELfs-sHm_f8StAdL/view?usp=sharing) <br> [Соколов про t-SNE](https://drive.google.com/file/d/10QOcmthhxBJs4Wf2F26-fECwLMuyxCCd/view?usp=sharingГиперссылка) (Обратите внимание, что там потерян минус в определении условных вероятностей p и q)| [Семинарские задачи](https://www.overleaf.com/read/xpvbtnsybxzd) |
| Байесовские методы | Основные <br> [Дьяконов Байесовский подход в ML](https://dyakonov.org/2018/07/30/байесовский-подход/) <br>  [Соколов ЕМ](https://drive.google.com/file/d/19vRAxRn6xEovWYI6hJv8SmLS2E5-Y8Qj/view?usp=sharing) <br> [Соколов plsa](https://drive.google.com/file/d/10ljjGCZdZP1jX-xEDg24GkKU4yVfcQDV/view?usp=sharing) <br> [Соколов ЕМ для PCA](https://drive.google.com/file/d/16R14z9NLWWpO9CTNc9fCy7FHH2fzDbfr/view?usp=sharing) <br> _________________________________ <br> Дополнительно <br> [Воронцов Topic modelling (presentation)](https://drive.google.com/file/d/1U1g-SNLR5XocQtG77cS510-kFvj3Yfol/view?usp=sharing) <br> [Ветров Bayes PCA](https://drive.google.com/file/d/1pMiJUgCAgMNTLYJw60PpQ_wvWjD34P2E/view?usp=sharing) <br> [Воронцов Topic modeilling (pdf)](https://drive.google.com/file/d/195S8BPIXoMi9VvtmsnBp5YwMUPp89nKZ/view?usp=sharing) <br> [Курс ФКН по байесовским методам](http://wiki.cs.hse.ru/Байесовские_методы_машинного_обучения_2020) | [Семинарские задачи](https://www.overleaf.com/read/wcthtfxzsdkm) |
| Bias-variance decomposition | Основные <br> [Соколов BVD](https://drive.google.com/file/d/1T8I4WDoDfv9Zla0RG6hzV6QHkfooVJAu/view?usp=sharing) <br> [Дьяконов BVD](https://drive.google.com/file/d/1vnApYwcPweyGxKBwf1CpYGitRRwF_NFj/view?usp=sharing) <br> _________________________________ <br> Дополнительно <br> [BVD для линейной регрессии](https://drive.google.com/file/d/1coJclg1rZbk05V7myDka24mxMkV1kVsO/view?usp=sharing) <br> [BVD для K-NN](https://drive.google.com/file/d/1mFkBjYQZDDsw4SLDv87yk5d2lC0BlwmS/view?usp=sharing) | [Семинарские задачи](https://www.overleaf.com/read/hxphfvdpvkmk) |
| Ансамбли | Градиентный бустинг <br> [Соколов бутстрэп и AdaBoost](https://drive.google.com/file/d/1U1K32HvSaHPW9FRtOn9Ps5vKZdVRRnl7/view?usp=sharing) <br> [Соколов Градиентный бустинг](https://drive.google.com/file/d/1rRefOlOEx_70QsM4sFEff1tN1vSeXHmC/view?usp=sharing) <br> [Дьяконов Градиентный бустинг](https://drive.google.com/file/d/1GmV9uuGq6Z8eLr3dCJmZUcjul-gbIgWz/view?usp=sharing) <br> [Соколов Градиентный бустинг (вопросы и ответы)](https://drive.google.com/file/d/1rnBOF10Gy2y8n3Ji9P51EHckXqPenvlC/view?usp=sharing) <br> [Соколов XGBoost](https://drive.google.com/file/d/1Pruh5Bsq8EjmhvZ3dokP5hoFYt_h30SL/view?usp=sharing) <br> [Дьяконов Ансамбли](https://drive.google.com/file/d/1ofZsBhjQavCjHz3T6K_jJr6s7iz79zWv/view?usp=sharing) <br> [Дьяконов RF & GBM](https://drive.google.com/file/d/1LLJW7XE1T6jsk8Dm5KO_JHQjhrwVHo5g/view?usp=sharing) <br> _________________________________ <br> Стэкинг <br> [Гущин Stacking](https://drive.google.com/file/d/14YqFSQGkbbJWoO58FvpxfEa0sDlMZ2_-/view?usp=sharing) <br> [Дьяконов Stacking](https://dyakonov.org/2017/03/10/cтекинг-stacking-и-блендинг-blending/)  <br> _________________________________ <br> Дополнительно <br> [LighGBM paper](https://papers.nips.cc/paper/2017/file/6449f44a102fde848669bdd9eb6b76fa-Paper.pdf) <br> [CatBoost paper](https://arxiv.org/pdf/1706.09516.pdf) <br> [Bagging vs. Boosting](https://towardsdatascience.com/ensemble-learning-bagging-boosting-3098079e5422) <br> [Соколов Градиентный бустинг с картинками](https://drive.google.com/file/d/1wld4Jsy2A00mZQRfOlAgONqUzr33Xkes/view?usp=sharing) | [Семинарские задания](https://www.overleaf.com/read/jqybqsdrrgtt)
| Нейронные сети | <br> _________________________________ <br> Дополнительно <br> [Yann LeCun](https://atcold.github.io/pytorch-Deep-Learning/) |



### Материалы к экзамену:
1. [Билеты](https://www.overleaf.com/read/hgrkssyrztpd)
   - [Расписанные билеты](https://www.overleaf.com/read/vqdgddypzwsx)
2. [Теоретический минимум](https://www.overleaf.com/read/jyqfphfjrynj)
   - [Расписанный теормин](https://www.overleaf.com/read/hmrwwcpgxvxr)

#### Тесты:

[Минитест от Дьяконова](https://docs.google.com/forms/d/e/1FAIpQLScFNuftP6MHVMhGHKpCPJu9jWphSiCTBkP16U21tLMFdDQHFQ/viewform) - на знание ML

[Тест в компанию Plarium](https://docs.google.com/forms/d/1l_w5WK2TznaU_euDfZ5WRdJRmXzLKX8lvetwerYLAu0/viewform?ts=5bd2c592&edit_requested=true)

[Тест в компанию Алгомост](https://algomost.typeform.com/to/NWgrbB?typeform-source=www.algomost.com)

#### Полезные ссылки:

[Учебник по ML от ШАД](https://ml-handbook.ru/)

[Анализ малых данных](https://dyakonov.org/) - блог Дьяконова о машинном обучении

[Гитхаб Дьяконова](https://github.com/Dyakonov?tab=repositories):

- [IML](https://github.com/Dyakonov/IML) - курс по машинному обучению для 1-2 курсов.
- [MLDM](https://github.com/Dyakonov/MLDM/tree/master/2019) - потоковый курс по ML для 3их курсов
- [DL](https://github.com/Dyakonov/DL) - курс по глубокому обучению

[Курсы ФКН](http://wiki.cs.hse.ru/Заглавная_страница):

- [Соколов. ML1](http://wiki.cs.hse.ru/Машинное_обучение_1/2020_2021)
- [Соколов. ML2](http://wiki.cs.hse.ru/Машинное_обучение_2)

[Книга Дмитрия Ефимова](https://drive.google.com/file/d/1MjnGKB8gIIUGk63PSNzLn3w0jI05XaI6/view?usp=sharing) (Есть примеры реализаций ML алгоритмов на голом питоне)