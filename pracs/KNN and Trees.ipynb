{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from tqdm import tqdm_notebook\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.rcParams['figure.figsize'] = (8, 8)\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 1. KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Все дальнейшие эксперименты задание №1 предлагается проводить на данных соревнования Amazon Employee Access Challenge: https://www.kaggle.com/c/amazon-employee-access-challenge\n",
    "\n",
    "В данной задаче предлагается предсказать, будет ли одобрен запрос сотрудника на получение доступа к тому или иному ресурсу. Все признаки являются категориальными.\n",
    "\n",
    "Для удобства данные можно загрузить по ссылке: https://www.dropbox.com/s/q6fbs1vvhd5kvek/amazon.csv\n",
    "\n",
    "Сразу прочитаем данные и создадим разбиение на обучение и контроль:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Считываем данные\n",
    "data = pd.read_csv('.../amazon.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# доля положительных примеров\n",
    "data.ACTION.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# число значений у признаков\n",
    "for col_name in data.columns:\n",
    "    print col_name, len(data[col_name].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# НЕ МЕНЯЕМ RANDOM_STATE!!!\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.iloc[:, 1:], data.iloc[:, 0],\n",
    "                                                    test_size=0.3, random_state=241)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 [2 балла]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуйте три функции расстояния на категориальных признаках, которые описаны [вот здесь](https://github.com/mmp-mmro-team/mmp_mmro_fall_2019/blob/master/lecture-notes/Sem03_knn.pdf).\n",
    "\n",
    "Проще всего будет определить метрики как [user-defined distance](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.DistanceMetric.html), после чего воспользоваться реализацией kNN из sklearn (в этом случае используйте функцию predict_proba). Можно реализовать метод k ближайших соседей и самостоятально — в этом случае учитите, что он должен возвращать оценку вероятности, то есть отношение объектов первого класса среди соседей к числу соседей).\n",
    "\n",
    "Постарайтесь уделить особое внимание эффективности кода — при реализации метрик \"в лоб\" вы можете столкнуться с очень большим временем выполнения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlap(x, z):\n",
    "    # Ваш код здесь\n",
    "    pass\n",
    "\n",
    "def flattened_overlap(x, z):\n",
    "    # Ваш код здесь\n",
    "    pass\n",
    "\n",
    "def log_overlap(x, z):\n",
    "    # Ваш код здесь\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 [1 балл]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подсчитайте для каждой из метрик качество на тестовой выборке X_test при числе соседей k=10. Мера качества — AUC-ROC.\n",
    "Какая функция расстояния оказалась лучшей?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ваш код здесь:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 [2 балла]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подберите лучшее (на тестовой выборке) число соседей k для каждой из функций расстояния. Какое наилучшее качество удалось получить?\n",
    "Для подбора можно использовать любые средства из sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ваш код здесь:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4 [6 баллов]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуйте [счётчики](https://github.com/mmp-mmro-team/mmp_mmro_fall_2019/blob/master/lecture-notes/Sem03_knn.pdf) для кодирование категориальных признаков."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А именно, каждый категориальный признак нужно заменить на три:\n",
    "\n",
    "<ul>\n",
    "<li>Число counts объектов в обучающей выборке с таким же значением признака.</li>\n",
    "\n",
    "<li>Число successes объектов первого класса (y=1) в обучающей выборке с таким же значением признака.</li>\n",
    "\n",
    "<li>Сглаженное отношение двух предыдущих величин: (successes + 1) / (counts + 2).</li>\n",
    "</ul>\n",
    "\n",
    "Поскольку признаки, содержащие информацию о целевой переменной, могут привести к переобучению, может оказаться полезным сделать фолдинг: разбить обучающую выборку на n частей, и для i-й части считать counts и successes по всем остальным частям. Для тестовой выборки используются счетчики, посчитанные по всей обучающей выборке. Реализуйте и такой вариант. Можно использовать n=3.\n",
    "\n",
    "Посчитайте на тесте AUC-ROC метода k ближайших соседей с евклидовой метрикой для выборки, где категориальные признаки заменены на счетчики. Сравните по AUC-ROC два варианта формирования выборки — с фолдингом и без. Не забудьте подобрать наилучшее число соседей k."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ваш код здесь:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.5 [3 балла]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавьте в исходную выборку парные признаки — то есть для каждой пары $(f_i,f_j), \\ i<j$ исходных категориальных признаков добавьте новый категориальный признак $f_{ij}$, значение которого является конкатенацией значений $f_i$ и $f_j$ (желательно через какой-нибудь специальный символ во избежание коллизий). Посчитайте счетчики для этой выборки, найдите качество метода k ближайших соседей с наилучшим k (с фолдингом и без)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ваш код здесь:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание  2. Решающее дерево"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 [10 баллов]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуйте свой класс Решающее дерево (для задачи классификации и регрессии). Шаблон класса представлен ниже, однако дерево не обязательно реализовывать именно по такому шаблону, главное, чтобы у ваше класса был метод .fit() - по двумерной матрице объект-признак и одномерному вектору таргетов получает оптимальные предикаты и метод .predict() - по двумерной матрице объект-признак возвращает одномерный вектор предсказаний.\n",
    "\n",
    "Построение дерева должно осуществляться согласно базовому жадному алгоритму. Выбор лучшего разбиения необходимо производить по критерию, поданному в качестве аргумента в init (\"Gini\" или \"Entropy\" - для задачи классификации и \"Variance\" - для задачи регрессии). Критерий останова: все объекты в листе относятся к одному классу. Ответ в листе: класс объектов, находящихся в нем. Для категориальных признаков необходимо выполнить преобразование, описанное на [семинаре](https://github.com/esokolov/ml-course-msu/blob/master/ML16/lecture-notes/Sem04_trees.pdf) в разделе \"Учет категориальных признаков\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTree:\n",
    "    def __init__(self, criterion):\n",
    "        \"\"\"\n",
    "        criterion: Какой критерий расщепления использовать: \"Gini\" или \"Entropy\" в случае \n",
    "        задачи классификации и \"Variance\" - в случае задачи регрессии \n",
    "        feature_numbers_and_splits - list список, содержащий оптимальные номера признаков и \n",
    "        разбиения. Пример: \n",
    "                [(0, 0.34), \n",
    "                           [(1, -1.16), \n",
    "                                       [(0, 13.53), \n",
    "                                                   [(), \n",
    "                                                    (0, 2.0), \n",
    "                                                           [(), \n",
    "                                                            ()]], \n",
    "                                        ()\n",
    "                                                        ], \n",
    "                            (4, -0.33), \n",
    "                                       [(),  \n",
    "                                        (3, 11.2), \n",
    "                                                   [(), \n",
    "                                                    ()]]]]\n",
    "        Этот список символизирует следующее дерево:\n",
    "                                    \n",
    "                                    [x_0 < 0.34]\n",
    "                                    /          \\\n",
    "                        [x_1 < -1.16]          [x_4 < -0.33]\n",
    "                        /          \\            /         \\\n",
    "                [x_0 < 13.53]     Лист       Лист       [x_3 < 11.2]\n",
    "                   /     \\                               /        \\\n",
    "                 Лист   [x_0 < 2.0]                    Лист      Лист\n",
    "                          /     \\ \n",
    "                        Лист    Лист\n",
    "        \"\"\"\n",
    "        self.criterion = criterion\n",
    "        self.feature_numbers_and_splits = []\n",
    "        # Здесь могут быть ещё какие-то параметры\n",
    "        \n",
    "    def criterion_count(self, node_y):\n",
    "        \"\"\"\n",
    "        node_y: np.array размера (|R|) - вектор таргетов, для объектов в этом листе.\n",
    "        \n",
    "        return:\n",
    "            node_criterion - float значения критерия ('Gini', 'Entropy' или 'Variance') для \n",
    "            листа, содержащего объекты с таргетами node_y\n",
    "        \"\"\"\n",
    "        # Ваш код здесь\n",
    "        \n",
    "        return node_critetion\n",
    "    \n",
    "    def _find_best_split(self, node_X, node_y):\n",
    "        \"\"\"\n",
    "        node_X: np.array размера (|R| x d) - матрица объект-признак. |R| - число объектов в \n",
    "        этом листе, d - число признаков. \n",
    "        node_y: np.array размера (|R|) - вектор таргетов, для объектов в этом листе.\n",
    "        \n",
    "        return: \n",
    "            best_feature_number - int номер признака от 0 до d-1 включительно, \n",
    "            дающего лучшее разбиение\n",
    "            best_split_value - float значения предиката для деления, которое обеспечивает\n",
    "            наибольшее значение критерия ('Gini', 'Entropy', 'Variance')\n",
    "        \"\"\"\n",
    "        # Ваш код здесь\n",
    "        \n",
    "        return best_feature_number, best_split_value\n",
    "\n",
    "        \n",
    "    def _split_leaf(self, node_X, node_y, feature_number, split_value):\n",
    "        \"\"\"\n",
    "        node_X: np.array размера (|R| x d) - матрица объект-признак. |R| - число объектов в \n",
    "        этом листе, d - число признаков. \n",
    "        node_y: np.array размера (|R|) - вектор таргетов, для объектов в этом листе.\n",
    "        feature_number: int номер признака от 0 до d-1 включительно, по которому произвести\n",
    "        разбиение листа на два\n",
    "        split_value: float трешхолд, по которому производить разбиение\n",
    "        Иными словами, предикат для разбиения выглядит так: [feature_number < split_value]\n",
    "        \n",
    "        return: \n",
    "        Возвращаем 4 объекта: \n",
    "                left_node_X (np.array размера (|Rl| x d)), \n",
    "                left_node_y (np.array размера (|Rl|)), \n",
    "                right_node_X (np.array размера (|Rr| x d)), \n",
    "                right_node_y (np.array размера (|Rr|))\n",
    "        \"\"\"\n",
    "        # Ваш код здесь\n",
    "        \n",
    "        return left_node_X, left_node_y, right_node_X, right_node_y\n",
    "\n",
    "    \n",
    "    def fit(self, X, y, cat_features, verbose=False):\n",
    "        \"\"\"\n",
    "        X - np.array размера (n x d) - матрица объект-признак для обучающей выборки, на которой\n",
    "        мы хотим обучить дерево\n",
    "        y - np.array размера (n) - вектор таргетов для обучающей выборки, на которой\n",
    "        мы хотим обучить дерево\n",
    "        verbose - (True/False) нужно ли выводить итерации обучения.\n",
    "        cat_features - np.array размера (d) - вектор из 0 и 1, символизирующий какие признаки\n",
    "        являются вещественными, а какие категориальными. (0 - признак вещественный, 1 - кате-\n",
    "        гориальный)\n",
    "        \n",
    "        return:\n",
    "            метод ничего не возвращает, но заполняет self.feature_numbers_and_splits, как \n",
    "            показано в init'e\n",
    "        \"\"\"\n",
    "        # Ваш код здесь\n",
    "        \n",
    "    def predict(self, X, cat_features):\n",
    "        \"\"\"\n",
    "        X - np.array размера (m x d) - матрица объект-признак для выборки, на которой хотим\n",
    "        получить предсказания.\n",
    "        cat_features - np.array размера (d) - вектор из 0 и 1, символизирующий какие признаки\n",
    "        являются вещественными, а какие категориальными. (0 - признак вещественный, 1 - кате-\n",
    "        гориальный)\n",
    "        \n",
    "        return:\n",
    "            y_pred - np.array размера (m) - вектор предсказаний для матрицы X.\n",
    "        \"\"\"\n",
    "        # Ваш код здесь\n",
    "        \n",
    "        return y_pred\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 [3 балла]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Протестируйте свое решающее дерево на датасете [mushrooms](https://archive.ics.uci.edu/ml/datasets/Mushroom). Вам нужно скачать таблицу agaricus-lepiota.data (из [Data Folder](https://archive.ics.uci.edu/ml/machine-learning-databases/mushroom/)), прочитать ее с помощью pandas, применить к каждому столбцу LabelEncoder (из sklearn), чтобы преобразовать строковые имена категорий в натуральные числа. Первый столбец - это целевая переменная (e-edible, p-poisonous) Мы будем измерять качество с помощью accuracy, так что нам не очень важно, что будет классом 1, а что - классом 0. Обучите решающее дерево на половине случайно выбранных объектов (признаки в датасете категориальные) и сделайте предсказания для оставшейся половины. Вычислите accuracy.\n",
    "\n",
    "У вас должно получиться значение accuracy, равное единице (или очень близкое к единице), и не очень глубокое дерево."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ваш код здесь:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3 [6 баллов]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузите следующие наборы данных (напомним, что pandas умеет загружать файлы по url, в нашем случае это файл *.data), предварительно ознакомившись с описанием признаков и целевой переменной в каждом из них (она записаны в Data Folder, в файле *.names):\n",
    "\n",
    "<ul>\n",
    "    \n",
    "<li> \n",
    "\n",
    "[mushrooms](https://archive.ics.uci.edu/ml/datasets/Mushroom) (загрузили в предыдущем пункте, классы записаны в нулевом столбце) \n",
    "</li>\n",
    "\n",
    "<li> \n",
    "\n",
    "[tic-rac-toe](https://archive.ics.uci.edu/ml/datasets/Tic-Tac-Toe+Endgame) (классы записаны в последнем столбце) \n",
    "</li>\n",
    "\n",
    "<li>\n",
    "    \n",
    "[cars](https://archive.ics.uci.edu/ml/datasets/Car+Evaluation) (классы записаны в последнем столбце, считаем что unacc, acc - это класс 0, good, vgood - класс 1)\n",
    "</li>\n",
    "\n",
    "<li>\n",
    "    \n",
    "[nurcery](https://archive.ics.uci.edu/ml/datasets/Nursery) (классы записаны в последнем столбце, считаем, что not_recom и recom - класс 0, very_recom, priority, spec_prior - класс 1)\n",
    "</li>\n",
    "</ul>\n",
    "\n",
    "Закодируйте категориальные признаки, использовав LabelEncoder. С помощью cross_val_score (cv=10) оцените accuracy на каждом из этих наборов данных следующих алгоритмов:\n",
    "\n",
    "<ul>\n",
    "<li>DecisionTree, считающий все признаки вещественными</li>\n",
    "\n",
    "<li>DecisionTree, считающий все признаки категориальными</li>\n",
    "\n",
    "<li>DecisionTree, считающий все признаки вещественными + one-hot-encoding всех признаков</li>\n",
    "\n",
    "<li>DecisionTreeClassifier из sklearn</li>\n",
    "</ul>\n",
    "\n",
    "Запишите результат в pd.DataFrame (по строкам - наборы данных, по столбцам - алгоритмы).\n",
    "Рекомендации:\n",
    "\n",
    "Чтобы cross_val_score вычисляла точность, нужно передать scorer=make_scorer(accuracy_score), обе фукнции из sklearn.metrics.\n",
    "Если вам позволяет память (а она скорее всего позволяет), указывайте параметр sparse=False в OneHotEncoder (если вы, конечно, используете его). Иначе вам придется добиваться того, чтобы ваша реализация дерева умела работать с разреженными матрицами (что тоже, в целом, не очень сложно)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ваш код здесь:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 3. Композиция деревьев"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 [3 балла]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузите датасет [winequality-red.csv](https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv) в датафрейм. Последний столбец - целевая переменная (содержит классы).\n",
    "\n",
    "С помощью cross_val_score с cv=5 оцените качество (accuracy) следующих классификаторов:\n",
    "<ul>\n",
    "<li>DecisionTreeClassifier</li>\n",
    "<li>BaggingClassifier со 100 деревьями</li>\n",
    "<li>BaggingClassifier со 100 деревьями; каждое дерево обучается только по половине случайно выбранных признаков (см. параметры метода)</li>\n",
    "<li>RandomForestClassifier со 100 деревьями</li>\n",
    "</ul>\n",
    "Значение получается шумное, но в целом у вас должно получиться, что качество возрастает с каждым следующим алгоритмом. Этот пример демонстрирует, что RandomForest - это более сложный алгоритм, чем бэггинг и бэггинг со случайными подпространствами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ваш код здесь:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
